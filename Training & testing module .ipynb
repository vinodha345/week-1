{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPm+LVEgbJxmAkOLxnrLclz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#REAL-TIME FABRIC CLASSIFICATION USING **ONNX** AND **COMPUTER VISION**\n","\n","\n","***Author: Vinodha.s***\n","\n","üß™ CLOTHING MATERIAL CLASSIFICATION ‚Äì TRAINING MODULE :\n","  Use this after model training (cloth_model_mobilenetv2.h5)\n","\n"],"metadata":{"id":"-PPQ2_uH3TYM"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import cv2\n","from PIL import Image\n","\n","# Paths and constants\n","DATASET_DIR = r\"C:\\Users\\vinod\\Downloads\\project\\dataset_split\"  # Base dir with 'train' and 'val' subfolders\n","IMG_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","MODEL_SAVE_PATH = \"cloth_model_mobilenetv2.h5\"\n","\n","import os\n","\n","# Define dataset folder paths\n","train_dir = r\"C:\\Users\\vinod\\Downloads\\project\\dataset_split\\train\"\n","val_dir = r\"C:\\Users\\vinod\\Downloads\\project\\dataset_split\\validation\"\n","\n","print(\"Train folder exists:\", os.path.exists(train_dir))\n","print(\"Validation folder exists:\", os.path.exists(val_dir))\n","\n","# Step 2: Check consistency\n","train_classes = sorted(os.listdir(train_dir))\n","val_classes = sorted(os.listdir(val_dir))\n","\n","print(\"\\nTrain classes:\", train_classes)\n","print(\"Validation classes:\", val_classes)\n","\n","missing_in_train = [cls for cls in val_classes if cls not in train_classes]\n","missing_in_val = [cls for cls in train_classes if cls not in val_classes]\n","\n","if missing_in_train:\n","    print(\"‚ö†Ô∏è Found in validation but missing in train:\", missing_in_train)\n","if missing_in_val:\n","    print(\"‚ö†Ô∏è Found in train but missing in validation:\", missing_in_val)\n","if not missing_in_train and not missing_in_val:\n","    print(\"‚úÖ Both train and validation have same class folders.\")\n","\n","\n","# Define train and val directories\n","#train_dir = os.path.join(DATASET_DIR, 'train')\n","#val_dir = os.path.join(DATASET_DIR, 'val')\n","\n","# Check if directories exist\n","if not os.path.exists(train_dir) or not os.path.exists(val_dir):\n","    raise FileNotFoundError(f\"Dataset directories not found. Ensure {train_dir} and {val_dir} exist and contain class subfolders with images.\")\n","\n","# Data augmentation (no validation_split needed since data is pre-split)\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=20,\n","    zoom_range=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True\n",")\n","\n","# Generators pointing directly to train and val folders\n","train_gen = datagen.flow_from_directory(\n","    train_dir,  # Points to 'train' folder\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical'\n",")\n","\n","val_gen = datagen.flow_from_directory(\n","    val_dir,  # Points to 'val' folder\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical'\n",")\n","\n","print(\"Train samples:\", train_gen.samples)\n","print(\"Validation samples:\", val_gen.samples)\n","print(\"Classes:\", train_gen.class_indices)\n","\n","\n","# Label mapping (should now show fabric classes like 'Cotton', 'Silk', etc.)\n","label_map = {v: k for k, v in train_gen.class_indices.items()}\n","print(\"Label map:\", label_map)\n","\n","# Model building\n","base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base.trainable = False\n","\n","model = models.Sequential([\n","    base,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dropout(0.3),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.2),\n","    layers.Dense(train_gen.num_classes, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.summary()\n","\n","# Callbacks\n","checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","\n","\n","# Training\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=EPOCHS,\n","    callbacks=[checkpoint, early_stopping]\n",")\n","\n","# Evaluation\n","loss, acc = model.evaluate(val_gen)\n","print(f\"Validation Accuracy: {acc * 100:.2f}%\")\n","\n","# Pie chart for accuracy\n","plt.figure(figsize=(6, 6))\n","plt.pie(\n","    [acc * 100, 100 - acc * 100],\n","    labels=['Correct', 'Incorrect'],\n","    autopct='%1.1f%%',\n","    startangle=90,\n","    colors=['#4CAF50', '#E57373']\n",")\n","plt.title(\"Model Accuracy on Validation Data\")\n","plt.show()\n","\n","# Fabric info dictionary\n","FABRIC_INFO = {\n","    \"Cotton\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"5-6 months\", \"recycle\": \"Yes\"},\n","    \"Silk\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"4-5 months\", \"recycle\": \"Limited\"},\n","    \"Wool\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"1-5 months\", \"recycle\": \"Yes\"},\n","    \"Linen\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"2-4 months\", \"recycle\": \"Yes\"},\n","    \"Denim\": {\"mix\": \"Cotton + Elastane\", \"bio\": \"Partial\", \"time\": \"10-12 months\", \"recycle\": \"Yes\"},\n","    \"Polyester\": {\"mix\": \"Pure (Synthetic)\", \"bio\": \"No\", \"time\": \"20-200 years\", \"recycle\": \"Yes\"},\n","    \"Nylon\": {\"mix\": \"Pure (Synthetic)\", \"bio\": \"No\", \"time\": \"30-40 years\", \"recycle\": \"Yes\"},\n","    \"Rayon\": {\"mix\": \"Semi-Synthetic\", \"bio\": \"Partial\", \"time\": \"1-2 years\", \"recycle\": \"Limited\"},\n","    \"Leather\": {\"mix\": \"Processed Animal Hide\", \"bio\": \"No\", \"time\": \"10-50 years\", \"recycle\": \"Hard\"},\n","    \"Velvet\": {\"mix\": \"Blended\", \"bio\": \"Depends\", \"time\": \"Varies\", \"recycle\": \"Depends\"}\n","}\n","\n","# Function to predict on a single image\n","def predict_image(model, img_path):\n","    if not os.path.exists(img_path):\n","        print(f\"Error: Image path {img_path} does not exist.\")\n","        return\n","\n","    img = Image.open(img_path).convert('RGB')\n","    img = img.resize(IMG_SIZE)\n","    arr = np.expand_dims(np.array(img) / 255.0, axis=0)\n","    pred = model.predict(arr)\n","    idx = np.argmax(pred)\n","    label = label_map[idx]\n","    conf = np.max(pred)\n","    info = FABRIC_INFO.get(label, {\"mix\": \"-\", \"bio\": \"-\", \"time\": \"-\", \"recycle\": \"-\"})\n","\n","    print(f\"\\nüßµ Type of cloth: {label}\")\n","    print(f\"‚ô¶Ô∏è Mixing Fabric: {info['mix']}\")\n","    print(f\"üå± Biodegradable: {info['bio']}\")\n","    print(f\"‚åõ Decomposition Time: {info['time']}\")\n","    print(f\"‚ôªÔ∏è Recyclable: {info['recycle']}\")\n","    print(f\"üìä Confidence: {conf * 100:.2f}%\")\n","# ----------------- Dataset Consistency Checker -----------------\n","# Collect actual class names from dataset\n","actual_classes = list(train_gen.class_indices.keys())\n","fabric_info_classes = list(FABRIC_INFO.keys())\n","\n","# Check 1: Classes in dataset but missing in FABRIC_INFO\n","missing_in_info = [c for c in actual_classes if c not in fabric_info_classes]\n","\n","# Check 2: Keys in FABRIC_INFO not present in dataset\n","missing_in_dataset = [c for c in fabric_info_classes if c not in actual_classes]\n","\n","print(\"\\n===== DATASET CONSISTENCY CHECK =====\")\n","print(\"Classes found in dataset:\", actual_classes)\n","if missing_in_info:\n","    print(\"‚ö†Ô∏è Missing in FABRIC_INFO:\", missing_in_info)\n","else:\n","    print(\"‚úÖ All dataset classes found in FABRIC_INFO.\")\n","\n","if missing_in_dataset:\n","    print(\"‚ÑπÔ∏è Extra keys in FABRIC_INFO not present in dataset:\", missing_in_dataset)\n","else:\n","    print(\"‚úÖ All FABRIC_INFO keys correspond to dataset classes.\")\n","print(\"====================================\\n\")\n","\n","\n","# Function for live prediction via webcam\n","def live_predict(model):\n","    cap = cv2.VideoCapture(0)\n","    if not cap.isOpened():\n","        print(\"Error: Could not access webcam.\")\n","        return\n","\n","    print(\"Press 'c' to capture and predict, 'q' to quit.\")\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        cv2.imshow('Webcam', frame)\n","        key = cv2.waitKey(1) & 0xFF\n","        if key == ord('c'):\n","            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            img = cv2.resize(img, IMG_SIZE)\n","            arr = np.expand_dims(img / 255.0, axis=0)\n","            pred = model.predict(arr)\n","            idx = np.argmax(pred)\n","            label = label_map[idx]\n","            info = FABRIC_INFO.get(label, {\"mix\": \"-\", \"bio\": \"-\", \"time\": \"-\", \"recycle\": \"-\"})\n","            print(f\"\\nPrediction: {label} | Mix: {info['mix']} | Bio: {info['bio']} | Time: {info['time']} | Recycle: {info['recycle']}\")\n","        elif key == ord('q'):\n","            break\n","    cap.release()\n","    cv2.destroyAllWindows()"],"metadata":{"id":"Xe_23oIo2j75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üß™ CLOTHING MATERIAL CLASSIFICATION ‚Äì TESTING  MODULE :\n","  Use this after downloading 0NNX- Testing Pipeline and Gradio-User Interface Tool."],"metadata":{"id":"xsR8jxqtOWzJ"}},{"cell_type":"code","source":["import gradio as gr\n","import onnxruntime as ort\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import io\n","from PIL import Image\n","\n","# Load the ONNX model\n","session = ort.InferenceSession(r\"C:\\Users\\vinod\\Downloads\\project\\AICTE\\model.onnx\")\n","input_name = session.get_inputs()[0].name\n","\n","# Fabric classes\n","classes = [\n","    \"Artificial_fur\", \"Artificial_leather\", \"Crepe\", \"Denim\", \"Felt\",\n","    \"Fleece\", \"Leather\", \"Linen\", \"Lut\", \"Nylon\", \"Polyester\", \"Satin\",\n","    \"Silk\", \"Suede\", \"Terrycloth\", \"Unclassified cloth\", \"Utilities\",\n","    \"Velvet\", \"Viscose\", \"Wool\"\n","    ]\n","\n","# Fabric info dictionary\n","fabric_info = {\n","    \"Cotton\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"5‚Äì6 months\", \"recycle\": \"Yes\"},\n","    \"Silk\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"4‚Äì5 months\", \"recycle\": \"Limited\"},\n","    \"Wool\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"1‚Äì5 months\", \"recycle\": \"Yes\"},\n","    \"Linen\": {\"mix\": \"Pure (Natural)\", \"bio\": \"Yes\", \"time\": \"2‚Äì4 months\", \"recycle\": \"Yes\"},\n","    \"Denim\": {\"mix\": \"Cotton + Elastane\", \"bio\": \"Partial\", \"time\": \"10‚Äì12 months\", \"recycle\": \"Yes\"},\n","    \"Polyester\": {\"mix\": \"Pure (Synthetic)\", \"bio\": \"No\", \"time\": \"20‚Äì200 years\", \"recycle\": \"Yes\"},\n","    \"Nylon\": {\"mix\": \"Pure (Synthetic)\", \"bio\": \"No\", \"time\": \"30‚Äì40 years\", \"recycle\": \"Yes\"},\n","    \"Rayon\": {\"mix\": \"Semi-Synthetic\", \"bio\": \"Partial\", \"time\": \"1‚Äì2 years\", \"recycle\": \"Limited\"},\n","    \"Leather\": {\"mix\": \"Processed Animal Hide\", \"bio\": \"No\", \"time\": \"10‚Äì50 years\", \"recycle\": \"Hard\"},\n","    \"Velvet\": {\"mix\": \"Blended\", \"bio\": \"Depends\", \"time\": \"Varies\", \"recycle\": \"Depends\"},\n","}\n","\n","# Prediction function\n","def classify_image(img):\n","    img = cv2.resize(img, (224, 224))\n","    img = np.expand_dims(img, axis=0).astype(np.float32)\n","    pred = session.run(None, {input_name: img})[0]\n","    result_index = np.argmax(pred)\n","    fabric = classes[result_index]\n","    confidence = np.max(pred) * 100\n","\n","    info = fabric_info.get(fabric, {\"mix\": \"Unknown\", \"bio\": \"Unknown\", \"decompose\": \"-\", \"recycle\": \"-\"})\n","\n","    # Create pie chart\n","    fig, ax = plt.subplots(figsize=(2.5, 2.5))  # smaller pie chart\n","    ax.pie([confidence, 100 - confidence],\n","           labels=[f\"Correct ({confidence:.1f}%)\", f\"Incorrect ({100 - confidence:.1f}%)\"],\n","           autopct='%1.1f%%')\n","    ax.set_title(\"Model Accuracy\")\n","    buf = io.BytesIO()\n","    plt.savefig(buf, format='png', bbox_inches=\"tight\")\n","    buf.seek(0)\n","    chart_img = Image.open(buf)\n","\n","    result_text = f\"\"\"\n","üßµ **Type of Cloth:** {fabric}\n","üîπ **Mixing Fabric:** {info.get('mix', 'Unknown')}\n","üå± **Biodegradable:** {info.get('bio', 'Unknown')}\n","üïì **Decomposition Time:** {info.get('time', 'Unknown')}\n","‚ôªÔ∏è **Recyclable:** {info.get('recycle', 'Unknown')}\n","üìä **Model Confidence:** {confidence:.2f}%\n","\"\"\"\n","\n","    return result_text, chart_img\n","\n","# Interface\n","with gr.Blocks(title=\"üß∂ Real-Time Fabric Classification System\") as iface:\n","    gr.Markdown(\n","        \"### üß• Vinodha's Fabric Classification Dashboard\\n\"\n","        \"Upload or capture an image of a fabric to predict its material type and view biodegradability details.\"\n","    )\n","\n","    with gr.Row(equal_height=True):\n","        image_input = gr.Image(type=\"numpy\", label=\"Upload or Capture Cloth Image\", height=300)\n","\n","    with gr.Row(equal_height=True):\n","        output_text = gr.Textbox(label=\"Prediction Details\", lines=9, max_lines=12, interactive=False)\n","        output_chart = gr.Image(label=\"Model Accuracy Chart\", height=250)\n","\n","    classify_btn = gr.Button(\"üîç Classify Fabric\")\n","\n","    classify_btn.click(fn=classify_image, inputs=image_input, outputs=[output_text, output_chart])\n","\n","iface.launch(inbrowser=True)\n","\n","\n","\n"],"metadata":{"id":"JRwguXl2PPi2"},"execution_count":null,"outputs":[]}]}